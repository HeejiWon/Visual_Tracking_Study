{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0606_Tracking_without_bells_n_whistles.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPNvTgNSx7dn3mKJJQoGXJw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"rZ7IKS5XyXYN"},"source":["## Tracking without bells and whistles\n","- Tracking without bells and whistles의 Tracktor.py에 해당하는 코드\n","- paper : https://arxiv.org/pdf/1903.05625.pdf\n","- code : https://github.com/phil-bergmann/tracking_wo_bnw\n"]},{"cell_type":"markdown","metadata":{"id":"IgY8LpNSrsbT"},"source":["#### Tracktor에 대한 설명\n","\n","- for t=0, detection의 결과로 tracker intialize\n","- for t>0, 2 step : __bbox regression, track intialization__\n","\n","#### Bouding box regression\n","- __$b^k_{t-1}$ 를 이용하여 $b_t^k$ 를 regression__\n","- Faster R-CNN의 경우에는, __이전 프레임 좌표에 대한 RoI pooling__을 현재 프레임에 대하여 적용 (가정 : high frame rates에 의해 target이 약간만 움직였을 것)\n","- 그래서 자동으로 __ID가 현재 프레임으로 이동__할 것이고, 이로 인해 짧은 trajectory가 만들어진다.\n","- tracjectory가 deactivating되는 두 가지 경우  \n","    ○ object가 프레임을 벗어나거나 non-object에 의해 가려지는 경우  \n","    ○ object간의 occlusion가 일어났을 때, 이에 대해  NMS를 적용하였더니 bouding box가 삭제되는 경우\n","\n","#### Bounding box initialization\n","- 이전 프레임에 등장하지 않았던 __새로운 target__ 또한 고려하기 위해 t시점의 전체 프레임에 대한 __detection $D_t$__ 가 주어진다. \n","- __$D_t$  중 active trajectories $b_t^k$ 와의 IoU가 $λ_new$ 보다 작은 경우에만 initialize__ (즉, 어떤 trajectory로도 설명되지 않는 새로운 tracklet를 만들어주기 위함)\n","- 주목할 점은 어떠한 tracking specific training이나 optimization을 필요로 하지 않고 단순히 object detection method에만 영향을 받는다는 점이다 (따라서 다른 dataset이나 scenarios에도 쉽게 적용가능)"]},{"cell_type":"code","metadata":{"id":"uVtfoYX7hhkr"},"source":["from collections import deque\n","\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from scipy.optimize import linear_sum_assignment\n","import cv2\n","\n","from .utils import bbox_overlaps, warp_pos, get_center, get_height, get_width, make_pos\n","\n","from torchvision.ops.boxes import clip_boxes_to_image, nms"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XDL9fdV5hcMt"},"source":["class Tracker:\n","    \"\"\"The main tracking file, here is where magic happens.\"\"\"\n","    # only track pedestrian\n","    cl = 1\n","\n","    def __init__(self, obj_detect, reid_network, tracker_cfg):\n","        self.obj_detect = obj_detect  # detection model  (Faster R-CNN 이용)\n","        self.reid_network = reid_network  # Siamese CNN (official에서는 resnet 이용)\n","        self.detection_person_thresh = tracker_cfg['detection_person_thresh']\n","        self.regression_person_thresh = tracker_cfg['regression_person_thresh']\n","        self.detection_nms_thresh = tracker_cfg['detection_nms_thresh']\n","        self.regression_nms_thresh = tracker_cfg['regression_nms_thresh']\n","        self.public_detections = tracker_cfg['public_detections']  # 공개 데이터셋 여부 (특정 모델의 result(pred bbox)를 들고 올 수 있는지)\n","        self.inactive_patience = tracker_cfg['inactive_patience']  # inactive되는 기간이 inactive patience 보다 길면 remove\n","        self.do_reid = tracker_cfg['do_reid']  # re-ID를 수행 여부 (T/F)\n","        self.max_features_num = tracker_cfg['max_features_num']  # Track에서 고려할 feature 수\n","        self.reid_sim_threshold = tracker_cfg['reid_sim_threshold']  # re-ID를 위한 similiarity measure (distance)에 대한 threshold \n","        self.reid_iou_threshold = tracker_cfg['reid_iou_threshold']  # re-ID를 위한 iou threshold\n","        self.do_align = tracker_cfg['do_align']  # ECC(Enhanced Correlation Coefficient)를 사용한 motion compensation 적용 여부\n","                                                 # 사용하지 않으면 적은 수치의 등속으로 가정\n","        self.motion_model_cfg = tracker_cfg['motion_model']  # moction compensation 사용여부\n","\n","\n","        self.warp_mode = getattr(cv2, tracker_cfg['warp_mode'])\n","        self.number_of_iterations = tracker_cfg['number_of_iterations']\n","        self.termination_eps = tracker_cfg['termination_eps']\n","\n","        self.tracks = []  # active tracks\n","        self.inactive_tracks = []  # inactive tracks\n","        self.track_num = 0  # 지금까지 만들어진 track 수 \n","        self.im_index = 0  # image index\n","        self.results = {}\n","\n","    # reset tracks\n","    def reset(self, hard=True):\n","        self.tracks = []  # tracker 초기화\n","        self.inactive_tracks = []\n","\n","        if hard:\n","            self.track_num = 0\n","            self.results = {}\n","            self.im_index = 0\n","\n","    # Make inactive tracks list \n","    def tracks_to_inactive(self, tracks):\n","        self.tracks = [t for t in self.tracks if t not in tracks]\n","        for t in tracks:\n","            t.pos = t.last_pos[-1]\n","        self.inactive_tracks += tracks\n","\n","    # Add New tracks\n","    def add(self, new_det_pos, new_det_scores, new_det_features):\n","        \"\"\"Initializes new Track objects and saves them.\"\"\"\n","        num_new = new_det_pos.size(0)  # size : 몇 개의 요소가 있는지 ex) 3*4인 2차원 array -> 12\n","        for i in range(num_new):\n","            self.tracks.append(Track(\n","                new_det_pos[i].view(1, -1),\n","                new_det_scores[i],\n","                self.track_num + i,\n","                new_det_features[i].view(1, -1),\n","                self.inactive_patience,\n","                self.max_features_num,\n","                self.motion_model_cfg['n_steps'] if self.motion_model_cfg['n_steps'] > 0 else 1\n","            ))\n","        self.track_num += num_new\n","\n","    def regress_tracks(self, blob):\n","        \"\"\"\n","        Regress the position of the tracks and also checks their scores.\n","        \"\"\"\n","        pos = self.get_pos()  # active track에 있는 positions (이전 프레임의 position) 가져오기\n","\n","        # regress\n","        boxes, scores = self.obj_detect.predict_boxes(pos)  # Facter RCNN의 RoI head 부분 (RoI Pooling하고, Bbox regression & Classification)\n","        pos = clip_boxes_to_image(boxes, blob['img'].shape[-2:])    # box가 image안에 포함되도록 image를 벗어나는 x, y 좌표 clamp해주기\n"," \n","        s = []\n","        for i in range(len(self.tracks) - 1, -1, -1):   # 뒤에서부터\n","            t = self.tracks[i]\n","            t.score = scores[i]\n","\n","            # score가 threshold보다 작으면 inactive (self.tracks에서 빼주고 inactive_tracks에 넣어주기)\n","            if scores[i] <= self.regression_person_thresh:  \n","                self.tracks_to_inactive([t])\n","            \n","            # score가 threshold보다 크면\n","            else:\n","                s.append(scores[i])\n","                t.pos = pos[i].view(1, -1)\n","\n","        return torch.Tensor(s[::-1]).cuda()  # 나중에 들어온 track에 대해서 먼저 score를 넣어줬기 때문에 list reverse\n","\n","    def get_pos(self):\n","        \"\"\"Get the positions of all active tracks.\"\"\"\n","        if len(self.tracks) == 1:\n","            pos = self.tracks[0].pos\n","        elif len(self.tracks) > 1:\n","            pos = torch.cat([t.pos for t in self.tracks], 0)\n","        else:\n","            pos = torch.zeros(0).cuda()\n","        return pos\n","\n","    def get_features(self):\n","        \"\"\"Get the features of all active tracks.\"\"\"\n","        if len(self.tracks) == 1:\n","            features = self.tracks[0].features\n","        elif len(self.tracks) > 1:\n","            features = torch.cat([t.features for t in self.tracks], 0)\n","        else:\n","            features = torch.zeros(0).cuda()\n","        return features\n","\n","    def get_inactive_features(self):\n","        \"\"\"Get the features of all inactive tracks.\"\"\"\n","        if len(self.inactive_tracks) == 1:\n","            features = self.inactive_tracks[0].features\n","        elif len(self.inactive_tracks) > 1:\n","            features = torch.cat([t.features for t in self.inactive_tracks], 0)\n","        else:\n","            features = torch.zeros(0).cuda()\n","        return features\n","\n","    def reid(self, blob, new_det_pos, new_det_scores):\n","        \"\"\"Tries to ReID inactive tracks with new detections.\"\"\"\n","        new_det_features = [torch.zeros(0).cuda() for _ in range(len(new_det_pos))]\n","\n","        if self.do_reid:\n","            # new_det_pos의 appearance feature 구하기\n","            # 이때 blob['img'] (BS, c, h, w)에 대해서 net_det_pos 부분을 crop해서 reid network에 forward 시킴\n","            new_det_features = self.reid_network.test_rois(\n","                blob['img'], new_det_pos).data\n","\n","            # inactive track과의 reID (active track과 matching된 게 없으므로)\n","            if len(self.inactive_tracks) >= 1:\n","\n","                # calculate appearance distances\n","                dist_mat, pos = [], []\n","                for t in self.inactive_tracks:\n","\n","                    # 기존 (inactive) track과의 appearance distance matrix\n","                    dist_mat.append(torch.cat([t.test_features(feat.view(1, -1))   \n","                                               for feat in new_det_features], dim=1))\n","                    pos.append(t.pos)\n","\n","                if len(dist_mat) > 1:\n","                    dist_mat = torch.cat(dist_mat, 0)\n","                    pos = torch.cat(pos, 0)\n","                else:\n","                    dist_mat = dist_mat[0]\n","                    pos = pos[0]\n","\n","                # calculate IoU distance (IoU가 threshold보다 작은 값들에 대해 dist_mat 행렬에 큰 값을 부여하기 위해, \n","                # 즉 거리를 멀게 하여 assignment를 어렵게 하기 위해)\n","                iou = bbox_overlaps(pos, new_det_pos)\n","                iou_mask = torch.ge(iou, self.reid_iou_threshold)\n","                iou_neg_mask = ~iou_mask\n","\n","                # make all impossible assignments to the same add big value\n","                dist_mat = dist_mat * iou_mask.float() + iou_neg_mask.float() * 1000  # iou가 threshold보다 작은 값들에 대하여 (iou_neg_mask) 1000를 더해줌\n","                dist_mat = dist_mat.cpu().numpy()\n","\n","                row_ind, col_ind = linear_sum_assignment(dist_mat)  # Hungarian algorithm을 이용해 assignment 해주기\n","                # row : inactive_tracks, col : new_det_pos\n","\n","                # row_ind, col_ind를 이용하여 row_ind에 해당하는 inactive_trackers를 self.tracks에 넣어주고,\n","                # position update, 새로 계산한 new_det_feature를 features에 add 해주기\n","                assigned = []\n","                remove_inactive = []\n","                for r, c in zip(row_ind, col_ind):\n","                    if dist_mat[r, c] <= self.reid_sim_threshold:\n","                        t = self.inactive_tracks[r]\n","                        self.tracks.append(t)\n","                        t.count_inactive = 0\n","                        t.pos = new_det_pos[c].view(1, -1)\n","                        t.reset_last_pos()\n","                        t.add_features(new_det_features[c].view(1, -1))\n","                        assigned.append(c)\n","                        remove_inactive.append(t)\n","\n","                for t in remove_inactive:\n","                    self.inactive_tracks.remove(t)\n","\n","                # re-ID되지 않은, 즉 처음으로 나온 object를 keep해서 이것을 리턴해줌\n","                keep = torch.Tensor([i for i in range(new_det_pos.size(0)) if i not in assigned]).long().cuda()\n","                if keep.nelement() > 0:\n","                    new_det_pos = new_det_pos[keep]\n","                    new_det_scores = new_det_scores[keep]\n","                    new_det_features = new_det_features[keep]\n","                else:\n","                    new_det_pos = torch.zeros(0).cuda()\n","                    new_det_scores = torch.zeros(0).cuda()\n","                    new_det_features = torch.zeros(0).cuda()\n","\n","        return new_det_pos, new_det_scores, new_det_features\n","\n","    def get_appearances(self, blob):\n","        \"\"\"Uses the siamese CNN to get the features for all active tracks.\"\"\"\n","        new_features = self.reid_network.test_rois(blob['img'], self.get_pos()).data\n","        return new_features\n","\n","    def add_features(self, new_features):\n","        \"\"\"Adds new appearance features to active tracks.\"\"\"\n","        for t, f in zip(self.tracks, new_features):\n","            t.add_features(f.view(1, -1))\n","\n","    def align(self, blob):\n","        \"\"\"Aligns the positions of active and inactive tracks depending on camera motion.\"\"\"\n","        if self.im_index > 0:\n","            im1 = np.transpose(self.last_image.cpu().numpy(), (1, 2, 0))\n","            im2 = np.transpose(blob['img'][0].cpu().numpy(), (1, 2, 0))\n","            im1_gray = cv2.cvtColor(im1, cv2.COLOR_RGB2GRAY)\n","            im2_gray = cv2.cvtColor(im2, cv2.COLOR_RGB2GRAY)\n","            warp_matrix = np.eye(2, 3, dtype=np.float32)\n","            criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, self.number_of_iterations,  self.termination_eps)\n","            cc, warp_matrix = cv2.findTransformECC(im1_gray, im2_gray, warp_matrix, self.warp_mode, criteria)\n","            warp_matrix = torch.from_numpy(warp_matrix)\n","\n","            for t in self.tracks:\n","                t.pos = warp_pos(t.pos, warp_matrix)\n","                # t.pos = clip_boxes(Variable(pos), blob['im_info'][0][:2]).data\n","\n","            if self.do_reid:\n","                for t in self.inactive_tracks:\n","                    t.pos = warp_pos(t.pos, warp_matrix)\n","\n","            if self.motion_model_cfg['enabled']:\n","                for t in self.tracks:\n","                    for i in range(len(t.last_pos)):\n","                        t.last_pos[i] = warp_pos(t.last_pos[i], warp_matrix)\n","\n","    def motion_step(self, track):\n","        \"\"\"Updates the given track's position by one step based on track.last_v\"\"\"\n","        if self.motion_model_cfg['center_only']:\n","            center_new = get_center(track.pos) + track.last_v\n","            track.pos = make_pos(*center_new, get_width(track.pos), get_height(track.pos))\n","        else:\n","            track.pos = track.pos + track.last_v\n","\n","    def motion(self):\n","        \"\"\"Applies a simple linear motion model that considers the last n_steps steps.\"\"\"\n","        for t in self.tracks:\n","            last_pos = list(t.last_pos)\n","\n","            # avg velocity between each pair of consecutive positions in t.last_pos\n","            if self.motion_model_cfg['center_only']:\n","                vs = [get_center(p2) - get_center(p1) for p1, p2 in zip(last_pos, last_pos[1:])]\n","            else:\n","                vs = [p2 - p1 for p1, p2 in zip(last_pos, last_pos[1:])]\n","\n","            t.last_v = torch.stack(vs).mean(dim=0)  \n","            self.motion_step(t)\n","\n","        if self.do_reid:\n","            for t in self.inactive_tracks:\n","                if t.last_v.nelement() > 0:\n","                    self.motion_step(t)\n","\n","\n","    def step(self, blob):\n","        \"\"\"\n","        매 시점마다 실행되는 함수\n","\n","        This function should be called every timestep to perform tracking with a blob\n","        containing the image information.\n","        \"\"\"\n","\n","        # 각 track들의 현재 pos를 last_pos에 append\n","        for t in self.tracks:\n","            t.last_pos.append(t.pos.clone())\n","\n","        ###########################\n","        # Look for new detections #\n","        ###########################\n","        '''\n","        공개된 데이터셋이라면 그 결과(detection 결과)를 이용하고 아니라면 detection 진행\n","        detect된 box가 있다면 해당 box와 score를 det_pos, det_score로 설정\n","        '''\n","\n","        self.obj_detect.load_image(blob['img'])\n","\n","        # 공개된 데이터셋이면 결과가 있으므로 그 결과를 이용\n","        if self.public_detections:\n","            dets = blob['dets'].squeeze(dim=0)  # dets를 가져옴\n","            \n","            # dets가 있으면, RPN(Region Proposal Network)를 진행하지 않고 bbox regression과 classification만 진행\n","            if dets.nelement() > 0:\n","                boxes, scores = self.obj_detect.predict_boxes(dets)\n","            # dets가 없으면 boxes와 scores를 빈 텐서로 만들어줌\n","            else:\n","                boxes = scores = torch.zeros(0).cuda()\n","\n","        # 공개된 데이터셋이 아니면 detection 진행\n","        else:\n","            boxes, scores = self.obj_detect.detect(blob['img'])\n","\n","\n","        # boxes가 있다면 image안에 들어오도록 좌표를 clamp 해줌\n","        if boxes.nelement() > 0:\n","            boxes = clip_boxes_to_image(boxes, blob['img'].shape[-2:])\n","\n","            # Filter out tracks that have too low person score\n","            inds = torch.gt(scores, self.detection_person_thresh).nonzero().view(-1)  \n","                # torch.gt : Computes \\text{input} > \\text{other}input>other element-wise.\n","        else:\n","            inds = torch.zeros(0).cuda()\n","\n","        # inds가 있다면 해당 boxes, score를 det_pos, det_scores로 설정\n","        if inds.nelement() > 0:\n","            det_pos = boxes[inds]\n","            det_scores = scores[inds]\n","        else:\n","            det_pos = torch.zeros(0).cuda()\n","            det_scores = torch.zeros(0).cuda()\n","\n","        ##################\n","        # Predict tracks #\n","        ##################\n","        '''\n","        카메라 Motion 기반 조정 및 box regression\n","        '''\n","\n","        num_tracks = 0\n","        nms_inp_reg = torch.zeros(0).cuda()\n","\n","        # tracks이 하나라도 있으면\n","        if len(self.tracks):\n","\n","            # align \n","            # 카메라 모션에 따라 active/inactive tracks의 position을 align\n","            if self.do_align:\n","                self.align(blob)\n","\n","            # apply motion model\n","            if self.motion_model_cfg['enabled']:\n","                self.motion()\n","                self.tracks = [t for t in self.tracks if t.has_positive_area()]  # area가 양수인 것만 self.tracks로!\n","\n","            # regress\n","            person_scores = self.regress_tracks(blob)\n","\n","            if len(self.tracks):\n","                # NMS를 통해 keep할 track/inactive track 분리하기\n","                keep = nms(self.get_pos(), person_scores, self.regression_nms_thresh)\n","                self.tracks_to_inactive([self.tracks[i] for i in list(range(len(self.tracks))) if i not in keep])\n","\n","                # do_reid 이면 appearance vector 구해서 track에 feature 넣어주기\n","                if keep.nelement() > 0 and self.do_reid:\n","                        new_features = self.get_appearances(blob)\n","                        self.add_features(new_features)\n","\n","        #####################\n","        # Create new tracks #\n","        #####################\n","\n","        # 새로운 트랙이 생성될 때 (이전에 트랙한 object가 아니라고 판단 되었을 때)\n","\n","        # !!! Here NMS is used to filter out detections that are already covered by tracks. This is\n","        # !!! done by iterating through the active tracks one by one, assigning them a bigger score\n","        # !!! than 1 (maximum score for detections) and then filtering the detections with NMS.\n","        # !!! In the paper this is done by calculating the overlap with existing tracks, but the\n","        # !!! result stays the same.\n","\n","        # detection된 것이 하나라도 있으면 track들과 NMS 해주기\n","        if det_pos.nelement() > 0:\n","            keep = nms(det_pos, det_scores, self.detection_nms_thresh)\n","            det_pos = det_pos[keep]\n","            det_scores = det_scores[keep]\n","\n","            # 각 track에 대하여 det_pos와 비교\n","            # check with every track in a single run (problem if tracks delete each other)\n","            for t in self.tracks:\n","                nms_track_pos = torch.cat([t.pos, det_pos])  # track의 position과 det의 position concatenate\n","                nms_track_scores = torch.cat(\n","                    [torch.tensor([2.0]).to(det_scores.device), det_scores]) \n","                keep = nms(nms_track_pos, nms_track_scores, self.detection_nms_thresh)  # nms : return the indices\n","\n","                keep = keep[torch.ge(keep, 1)] - 1   # nms_track_pos에는 0번째 인덱스에 t.pos가 있기 때문에\n","                                                     # det_pos에서 keep할 index를 구해주기 위해서 \n","                                                     # 1보다 큰 keep(index)에 대해서 1 빼주기\n","                                                     # torch.ge : Computes input(왼)≥other(오) element-wise.        \n","                det_pos = det_pos[keep]\n","                det_scores = det_scores[keep]\n","                if keep.nelement() == 0:\n","                    break\n","\n","        # 모든 track과의 nms 적용 후, 살아남은 det_pos가 있다면 initialize\n","        if det_pos.nelement() > 0:\n","            new_det_pos = det_pos\n","            new_det_scores = det_scores\n","\n","            # re-ID matching을 해주고 matching되지 않은 (즉, 처음 나온) object를 리턴\n","            new_det_pos, new_det_scores, new_det_features = self.reid(blob, new_det_pos, new_det_scores)\n","\n","            # 새로운 object에 대한 tracker를 만들어주고 self.tracks에 추가해줌\n","            if new_det_pos.nelement() > 0:\n","                self.add(new_det_pos, new_det_scores, new_det_features)\n","\n","        ####################\n","        # Generate Results #\n","        ####################\n","\n","        for t in self.tracks:\n","            if t.id not in self.results.keys():\n","                self.results[t.id] = {}\n","            self.results[t.id][self.im_index] = np.concatenate([t.pos[0].cpu().numpy(), np.array([t.score])])\n","            # 즉, t.id : {\"im_index\" : [t.pos[0].cpu().numpy(), np.array([t.score])], ...}\n","\n","        # inactive track의 count_inactive +1 해주기\n","        for t in self.inactive_tracks:\n","            t.count_inactive += 1\n","\n","        # 정해준 임계값 (inactive_patience) 보다 count_inactive 큰 경우는 remove\n","        self.inactive_tracks = [\n","            t for t in self.inactive_tracks if t.has_positive_area() and t.count_inactive <= self.inactive_patience\n","        ]\n","\n","        self.im_index += 1  # image index\n","        self.last_image = blob['img'][0]\n","\n","    def get_results(self):\n","        return self.results\n","\n","\n","class Track(object):\n","    \"\"\"This class contains all necessary for every individual track.\"\"\"\n","\n","    def __init__(self, pos, score, track_id, features, inactive_patience, max_features_num, mm_steps):\n","        self.id = track_id\n","        self.pos = pos\n","        self.score = score\n","        self.features = deque([features])\n","        self.ims = deque([])\n","        self.count_inactive = 0\n","        self.inactive_patience = inactive_patience\n","        self.max_features_num = max_features_num\n","        self.last_pos = deque([pos.clone()], maxlen=mm_steps + 1)\n","        self.last_v = torch.Tensor([])\n","        self.gt_id = None\n","\n","    def has_positive_area(self):\n","        return self.pos[0, 2] > self.pos[0, 0] and self.pos[0, 3] > self.pos[0, 1]\n","\n","    def add_features(self, features):\n","        \"\"\"Adds new appearance features to the object.\"\"\"\n","        self.features.append(features)\n","        if len(self.features) > self.max_features_num:\n","            self.features.popleft()\n","\n","    def test_features(self, test_features):\n","        \"\"\"Compares test_features to features of this Track object\"\"\"\n","        if len(self.features) > 1:\n","            features = torch.cat(list(self.features), dim=0)\n","        else:\n","            features = self.features[0]\n","        features = features.mean(0, keepdim=True)\n","        dist = F.pairwise_distance(features, test_features, keepdim=True)\n","        return dist\n","\n","    def reset_last_pos(self):\n","        self.last_pos.clear()\n","        self.last_pos.append(self.pos.clone())"],"execution_count":null,"outputs":[]}]}
