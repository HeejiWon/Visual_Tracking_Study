{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ssd.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from layers import *\n",
    "from data import voc, coco\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSD(nn.Module):\n",
    "    \"\"\"Single Shot Multibox Architecture\n",
    "    The network is composed of a base VGG network followed by the\n",
    "    added multibox conv layers.  Each multibox layer branches into\n",
    "        1) conv2d for class conf scores\n",
    "        2) conv2d for localization predictions\n",
    "        3) associated priorbox layer to produce default bounding\n",
    "           boxes specific to the layer's feature map size.\n",
    "    See: https://arxiv.org/pdf/1512.02325.pdf for more details.\n",
    "    Args:\n",
    "        phase: (string) Can be \"test\" or \"train\"\n",
    "        size: input image size\n",
    "        base: VGG16 layers for input, size of either 300 or 500\n",
    "        extras: extra layers that feed to multibox loc and conf layers\n",
    "        head: \"multibox head\" consists of loc and conf conv layers\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, phase, size, base, extras, head, num_classes):\n",
    "        super(SSD, self).__init__()\n",
    "        self.phase = phase\n",
    "        self.num_classes = num_classes\n",
    "        self.cfg = (coco, voc)[num_classes == 21]\n",
    "        self.priorbox = PriorBox(self.cfg)\n",
    "        self.priors = Variable(self.priorbox.forward(), volatile=True)\n",
    "        self.size = size\n",
    "\n",
    "        # SSD network\n",
    "        self.vgg = nn.ModuleList(base)\n",
    "        \n",
    "        # Layer learns to scale the l2 normalized features from conv4_3\n",
    "        self.L2Norm = L2Norm(512, 20)\n",
    "        self.extras = nn.ModuleList(extras)\n",
    "\n",
    "        self.loc = nn.ModuleList(head[0])\n",
    "        self.conf = nn.ModuleList(head[1])\n",
    "\n",
    "        if phase == 'test':\n",
    "            self.softmax = nn.Softmax(dim=-1)\n",
    "            self.detect = Detect(num_classes, 0, 200, 0.01, 0.45)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Applies network layers and ops on input image(s) x.\n",
    "        Args:\n",
    "            x: input image or batch of images. Shape: [batch,3,300,300].\n",
    "        Return:\n",
    "            Depending on phase:\n",
    "            test:\n",
    "                Variable(tensor) of output class label predictions,\n",
    "                confidence score, and corresponding location predictions for\n",
    "                each object detected. Shape: [batch,topk,7]\n",
    "            train:\n",
    "                list of concat outputs from:\n",
    "                    1: confidence layers, Shape: [batch*num_priors, num_classes]\n",
    "                    2: localization layers, Shape: [batch, num_priors*4]\n",
    "                    3: priorbox layers, Shape: [2, num_priors*4]\n",
    "        \"\"\"\n",
    "        sources = list()\n",
    "        loc = list()\n",
    "        conf = list()\n",
    "\n",
    "        # apply vgg up to conv4_3 relu\n",
    "        for k in range(23):\n",
    "            x = self.vgg[k](x)\n",
    "\n",
    "        s = self.L2Norm(x)\n",
    "        sources.append(s)\n",
    "\n",
    "        # apply vgg up to fc7\n",
    "        for k in range(23, len(self.vgg)):\n",
    "            x = self.vgg[k](x)\n",
    "        sources.append(x)\n",
    "\n",
    "        # apply extra layers and cache source layer outputs\n",
    "        for k, v in enumerate(self.extras):\n",
    "            x = F.relu(v(x), inplace=True)\n",
    "            if k % 2 == 1:\n",
    "                sources.append(x)\n",
    "\n",
    "        # apply multibox head to source layers\n",
    "        for (x, l, c) in zip(sources, self.loc, self.conf):\n",
    "            loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
    "            conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
    "\n",
    "        loc = torch.cat([o.view(o.size(0), -1) for o in loc], 1)\n",
    "        conf = torch.cat([o.view(o.size(0), -1) for o in conf], 1\n",
    "                         \n",
    "        if self.phase == \"test\":\n",
    "            output = self.detect(\n",
    "                loc.view(loc.size(0), -1, 4),                   # loc preds\n",
    "                self.softmax(conf.view(conf.size(0), -1,\n",
    "                             self.num_classes)),                # conf preds\n",
    "                self.priors.type(type(x.data))                  # default boxes\n",
    "            )\n",
    "                         \n",
    "        else:\n",
    "            output = (\n",
    "                loc.view(loc.size(0), -1, 4),\n",
    "                conf.view(conf.size(0), -1, self.num_classes),\n",
    "                self.priors\n",
    "            )\n",
    "                         \n",
    "        return output\n",
    "\n",
    "    def load_weights(self, base_file):\n",
    "        other, ext = os.path.splitext(base_file)\n",
    "        if ext == '.pkl' or '.pth':\n",
    "            print('Loading weights into state dict...')\n",
    "            self.load_state_dict(torch.load(base_file,\n",
    "                                 map_location=lambda storage, loc: storage))\n",
    "            print('Finished!')\n",
    "        else:\n",
    "            print('Sorry only .pth and .pkl files supported.')\n",
    "\n",
    "\n",
    "# This function is derived from torchvision VGG make_layers()\n",
    "# https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\n",
    "def vgg(cfg, i, batch_norm=False):\n",
    "                         \n",
    "    '''\n",
    "    vgg size에 따라 vgg model을 만들어주는 함수\n",
    "    input : \n",
    "        cgf : \n",
    "            아래의 base dictionary에 따른 layer list\n",
    "            아래는 size가 300인 경우의 input 값\n",
    "            input = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'C', 512, 512, 512, \n",
    "                    'M', 512, 512, 512]\n",
    "        i : input channel\n",
    "    '''\n",
    "                         \n",
    "    layers = []\n",
    "    in_channels = i\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        elif v == 'C':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    pool5 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "    conv6 = nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6)\n",
    "    conv7 = nn.Conv2d(1024, 1024, kernel_size=1)\n",
    "    layers += [pool5, conv6,\n",
    "               nn.ReLU(inplace=True), conv7, nn.ReLU(inplace=True)]\n",
    "    return layers\n",
    "\n",
    "\n",
    "def add_extras(cfg, i, batch_norm=False):\n",
    "    # Extra layers added to VGG for feature scaling\n",
    "    layers = []\n",
    "    in_channels = i\n",
    "    flag = False\n",
    "    for k, v in enumerate(cfg):\n",
    "        if in_channels != 'S':\n",
    "            if v == 'S':\n",
    "                layers += [nn.Conv2d(in_channels, cfg[k + 1],\n",
    "                           kernel_size=(1, 3)[flag], stride=2, padding=1)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, v, kernel_size=(1, 3)[flag])]\n",
    "            flag = not flag\n",
    "        in_channels = v\n",
    "    return layers\n",
    "\n",
    "                         \n",
    "def multibox(vgg, extra_layers, cfg, num_classes):\n",
    "    '''\n",
    "    vgg, extra_layers, cfg, num_classes를 입력으로 받아 최종모델을 리턴하는 함수\n",
    "    '''\n",
    "                         \n",
    "    loc_layers = []\n",
    "    conf_layers = []\n",
    "    vgg_source = [21, -2]\n",
    "    for k, v in enumerate(vgg_source):\n",
    "        loc_layers += [nn.Conv2d(vgg[v].out_channels,\n",
    "                                 cfg[k] * 4, kernel_size=3, padding=1)]\n",
    "        conf_layers += [nn.Conv2d(vgg[v].out_channels,\n",
    "                        cfg[k] * num_classes, kernel_size=3, padding=1)]\n",
    "    for k, v in enumerate(extra_layers[1::2], 2):\n",
    "        loc_layers += [nn.Conv2d(v.out_channels, cfg[k]\n",
    "                                 * 4, kernel_size=3, padding=1)]\n",
    "        conf_layers += [nn.Conv2d(v.out_channels, cfg[k]\n",
    "                                  * num_classes, kernel_size=3, padding=1)]\n",
    "    return vgg, extra_layers, (loc_layers, conf_layers)\n",
    "\n",
    "\n",
    "base = {\n",
    "    '300': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'C', 512, 512, 512, 'M',\n",
    "            512, 512, 512],\n",
    "    '512': [],\n",
    "}\n",
    "extras = {\n",
    "    '300': [256, 'S', 512, 128, 'S', 256, 128, 256, 128, 256],\n",
    "    '512': [],\n",
    "}\n",
    "mbox = {\n",
    "    '300': [4, 6, 6, 6, 4, 4],  # number of boxes per feature map location\n",
    "    '512': [],\n",
    "}\n",
    "\n",
    "def build_ssd(phase, size=300, num_classes=21):\n",
    "    '''\n",
    "    phase, size 등을 입력으로 받아 SSD 모델 객체를 만들어주는 함수\n",
    "    '''\n",
    "                         \n",
    "    if phase != \"test\" and phase != \"train\":\n",
    "        print(\"ERROR: Phase: \" + phase + \" not recognized\")\n",
    "        return\n",
    "    if size != 300:\n",
    "        print(\"ERROR: You specified size \" + repr(size) + \". However, \" +\n",
    "              \"currently only SSD300 (size=300) is supported!\")\n",
    "        return\n",
    "    base_, extras_, head_ = multibox(vgg(base[str(size)], 3),\n",
    "                                     add_extras(extras[str(size)], 1024),\n",
    "                                     mbox[str(size)], num_classes)\n",
    "    return SSD(phase, size, base_, extras_, head_, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *\n",
    "from utils.augmentations import SSDAugmentation\n",
    "from layers.modules import MultiBoxLoss\n",
    "from ssd import build_ssd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.init as init\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2bool(v):\n",
    "    return v.lower() in (\"yes\", \"true\", \"t\", \"1\")\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='Single Shot MultiBox Detector Training With Pytorch')\n",
    "train_set = parser.add_mutually_exclusive_group()\n",
    "parser.add_argument('--dataset', default='VOC', choices=['VOC', 'COCO'],\n",
    "                    type=str, help='VOC or COCO')\n",
    "parser.add_argument('--dataset_root', default=VOC_ROOT,\n",
    "                    help='Dataset root directory path')\n",
    "parser.add_argument('--basenet', default='vgg16_reducedfc.pth',\n",
    "                    help='Pretrained base model')\n",
    "parser.add_argument('--batch_size', default=32, type=int,\n",
    "                    help='Batch size for training')\n",
    "parser.add_argument('--resume', default=None, type=str,\n",
    "                    help='Checkpoint state_dict file to resume training from')\n",
    "parser.add_argument('--start_iter', default=0, type=int,\n",
    "                    help='Resume training at this iter')\n",
    "parser.add_argument('--num_workers', default=4, type=int,\n",
    "                    help='Number of workers used in dataloading')\n",
    "parser.add_argument('--cuda', default=True, type=str2bool,\n",
    "                    help='Use CUDA to train model')\n",
    "parser.add_argument('--lr', '--learning-rate', default=1e-3, type=float,\n",
    "                    help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float,\n",
    "                    help='Momentum value for optim')\n",
    "parser.add_argument('--weight_decay', default=5e-4, type=float,\n",
    "                    help='Weight decay for SGD')\n",
    "parser.add_argument('--gamma', default=0.1, type=float,\n",
    "                    help='Gamma update for SGD')\n",
    "parser.add_argument('--visdom', default=False, type=str2bool,\n",
    "                    help='Use visdom for loss visualization')\n",
    "parser.add_argument('--save_folder', default='weights/',\n",
    "                    help='Directory for saving checkpoint models')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda 이용가능여부에 따라 torch tensor type 설정해주기\n",
    "if torch.cuda.is_available():\n",
    "    if args.cuda:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    if not args.cuda:\n",
    "        print(\"WARNING: It looks like you have a CUDA device, but aren't \" +\n",
    "              \"using CUDA.\\nRun with --cuda for optimal training speed.\")\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "if not os.path.exists(args.save_folder):\n",
    "    os.mkdir(args.save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \n",
    "    # Create dataset \n",
    "    if args.dataset == 'COCO':\n",
    "        if args.dataset_root == VOC_ROOT:\n",
    "            if not os.path.exists(COCO_ROOT):\n",
    "                parser.error('Must specify dataset_root if specifying dataset')\n",
    "            print(\"WARNING: Using default COCO dataset_root because \" +\n",
    "                  \"--dataset_root was not specified.\")\n",
    "            args.dataset_root = COCO_ROOT\n",
    "        cfg = coco\n",
    "        dataset = COCODetection(root=args.dataset_root,\n",
    "                                transform=SSDAugmentation(cfg['min_dim'],\n",
    "                                                          MEANS))\n",
    "    elif args.dataset == 'VOC':\n",
    "        if args.dataset_root == COCO_ROOT:\n",
    "            parser.error('Must specify dataset if specifying dataset_root')\n",
    "        cfg = voc\n",
    "        dataset = VOCDetection(root=args.dataset_root,\n",
    "                               transform=SSDAugmentation(cfg['min_dim'],\n",
    "                                                         MEANS))\n",
    "\n",
    "    if args.visdom:\n",
    "        import visdom\n",
    "        viz = visdom.Visdom()\n",
    "\n",
    "    ssd_net = build_ssd('train', cfg['min_dim'], cfg['num_classes'])\n",
    "    net = ssd_net\n",
    "\n",
    "    if args.cuda:\n",
    "        net = torch.nn.DataParallel(ssd_net)\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    if args.resume:\n",
    "        print('Resuming training, loading {}...'.format(args.resume))\n",
    "        ssd_net.load_weights(args.resume)\n",
    "    else:\n",
    "        vgg_weights = torch.load(args.save_folder + args.basenet)\n",
    "        print('Loading base network...')\n",
    "        ssd_net.vgg.load_state_dict(vgg_weights)\n",
    "\n",
    "    if args.cuda:\n",
    "        net = net.cuda()\n",
    "\n",
    "    if not args.resume:\n",
    "        print('Initializing weights...')\n",
    "        # initialize newly added layers' weights with xavier method\n",
    "        ssd_net.extras.apply(weights_init)\n",
    "        ssd_net.loc.apply(weights_init)\n",
    "        ssd_net.conf.apply(weights_init)\n",
    "\n",
    "    optimizer = optim.SGD(net.parameters(), lr=args.lr, momentum=args.momentum,\n",
    "                          weight_decay=args.weight_decay)\n",
    "    criterion = MultiBoxLoss(cfg['num_classes'], 0.5, True, 0, True, 3, 0.5,\n",
    "                             False, args.cuda)\n",
    "\n",
    "    net.train()\n",
    "    # loss counters\n",
    "    loc_loss = 0\n",
    "    conf_loss = 0\n",
    "    epoch = 0\n",
    "    print('Loading the dataset...')\n",
    "\n",
    "    epoch_size = len(dataset) // args.batch_size\n",
    "    print('Training SSD on:', dataset.name)\n",
    "    print('Using the specified args:')\n",
    "    print(args)\n",
    "\n",
    "    step_index = 0\n",
    "\n",
    "    if args.visdom:\n",
    "        vis_title = 'SSD.PyTorch on ' + dataset.name\n",
    "        vis_legend = ['Loc Loss', 'Conf Loss', 'Total Loss']\n",
    "        iter_plot = create_vis_plot('Iteration', 'Loss', vis_title, vis_legend)\n",
    "        epoch_plot = create_vis_plot('Epoch', 'Loss', vis_title, vis_legend)\n",
    "\n",
    "    data_loader = data.DataLoader(dataset, args.batch_size,\n",
    "                                  num_workers=args.num_workers,\n",
    "                                  shuffle=True, collate_fn=detection_collate,\n",
    "                                  pin_memory=True)\n",
    "    # create batch iterator\n",
    "    batch_iterator = iter(data_loader)\n",
    "    for iteration in range(args.start_iter, cfg['max_iter']):\n",
    "        '''\n",
    "        args.start_iter : Resume training at this iter\n",
    "        '''\n",
    "        \n",
    "        if args.visdom and iteration != 0 and (iteration % epoch_size == 0):\n",
    "            update_vis_plot(epoch, loc_loss, conf_loss, epoch_plot, None,\n",
    "                            'append', epoch_size)\n",
    "            # reset epoch loss counters\n",
    "            loc_loss = 0\n",
    "            conf_loss = 0\n",
    "            epoch += 1\n",
    "\n",
    "        # 지정한 step마다 lr 조정해주기\n",
    "        if iteration in cfg['lr_steps']:\n",
    "            step_index += 1\n",
    "            adjust_learning_rate(optimizer, args.gamma, step_index)\n",
    "\n",
    "        # load train data\n",
    "        images, targets = next(batch_iterator)\n",
    "\n",
    "        if args.cuda:\n",
    "            images = Variable(images.cuda())\n",
    "            targets = [Variable(ann.cuda(), volatile=True) for ann in targets]\n",
    "        else:\n",
    "            images = Variable(images)\n",
    "            targets = [Variable(ann, volatile=True) for ann in targets]\n",
    "            \n",
    "        # forward\n",
    "        t0 = time.time()\n",
    "        out = net(images)\n",
    "        \n",
    "        # backprop\n",
    "        optimizer.zero_grad()  # 역전파 전, gradient 0으로 초기화\n",
    "        loss_l, loss_c = criterion(out, targets)  # MultiBoxLoss 함수를 이용하여 loss 계산\n",
    "        loss = loss_l + loss_c\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t1 = time.time()\n",
    "        loc_loss += loss_l.data[0]\n",
    "        conf_loss += loss_c.data[0]\n",
    "\n",
    "        if iteration % 10 == 0:\n",
    "            print('timer: %.4f sec.' % (t1 - t0))\n",
    "            print('iter ' + repr(iteration) + ' || Loss: %.4f ||' % (loss.data[0]), end=' ')\n",
    "\n",
    "        if args.visdom:\n",
    "            update_vis_plot(iteration, loss_l.data[0], loss_c.data[0],\n",
    "                            iter_plot, epoch_plot, 'append')\n",
    "\n",
    "        if iteration != 0 and iteration % 5000 == 0:\n",
    "            print('Saving state, iter:', iteration)\n",
    "            torch.save(ssd_net.state_dict(), 'weights/ssd300_COCO_' +\n",
    "                       repr(iteration) + '.pth')\n",
    "    torch.save(ssd_net.state_dict(),\n",
    "               args.save_folder + '' + args.dataset + '.pth')\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, gamma, step):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 at every\n",
    "        specified step\n",
    "    # Adapted from PyTorch Imagenet example:\n",
    "    # https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "    \"\"\"\n",
    "    lr = args.lr * (gamma ** (step))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def xavier(param):\n",
    "    init.xavier_uniform(param)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        xavier(m.weight.data)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def create_vis_plot(_xlabel, _ylabel, _title, _legend):\n",
    "    return viz.line(\n",
    "        X=torch.zeros((1,)).cpu(),\n",
    "        Y=torch.zeros((1, 3)).cpu(),\n",
    "        opts=dict(\n",
    "            xlabel=_xlabel,\n",
    "            ylabel=_ylabel,\n",
    "            title=_title,\n",
    "            legend=_legend\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def update_vis_plot(iteration, loc, conf, window1, window2, update_type,\n",
    "                    epoch_size=1):\n",
    "    viz.line(\n",
    "        X=torch.ones((1, 3)).cpu() * iteration,\n",
    "        Y=torch.Tensor([loc, conf, loc + conf]).unsqueeze(0).cpu() / epoch_size,\n",
    "        win=window1,\n",
    "        update=update_type\n",
    "    )\n",
    "    # initialize epoch plot on first iteration\n",
    "    if iteration == 0:\n",
    "        viz.line(\n",
    "            X=torch.zeros((1, 3)).cpu(),\n",
    "            Y=torch.Tensor([loc, conf, loc + conf]).unsqueeze(0).cpu(),\n",
    "            win=window2,\n",
    "            update=True\n",
    "        )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Adapted from:\n",
    "    @longcw faster_rcnn_pytorch: https://github.com/longcw/faster_rcnn_pytorch\n",
    "    @rbgirshick py-faster-rcnn https://github.com/rbgirshick/py-faster-rcnn\n",
    "    Licensed under The MIT License [see LICENSE for details]\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from data import VOC_ROOT, VOCAnnotationTransform, VOCDetection, BaseTransform\n",
    "from data import VOC_CLASSES as labelmap\n",
    "import torch.utils.data as data\n",
    "\n",
    "from ssd import build_ssd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    import xml.etree.cElementTree as ET\n",
    "else:\n",
    "    import xml.etree.ElementTree as ET\n",
    "\n",
    "\n",
    "def str2bool(v):\n",
    "    return v.lower() in (\"yes\", \"true\", \"t\", \"1\")\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='Single Shot MultiBox Detector Evaluation')\n",
    "parser.add_argument('--trained_model',\n",
    "                    default='weights/ssd300_mAP_77.43_v2.pth', type=str,\n",
    "                    help='Trained state_dict file path to open')\n",
    "parser.add_argument('--save_folder', default='eval/', type=str,\n",
    "                    help='File path to save results')\n",
    "parser.add_argument('--confidence_threshold', default=0.01, type=float,\n",
    "                    help='Detection confidence threshold')\n",
    "parser.add_argument('--top_k', default=5, type=int,\n",
    "                    help='Further restrict the number of predictions to parse')\n",
    "parser.add_argument('--cuda', default=True, type=str2bool,\n",
    "                    help='Use cuda to train model')\n",
    "parser.add_argument('--voc_root', default=VOC_ROOT,\n",
    "                    help='Location of VOC root directory')\n",
    "parser.add_argument('--cleanup', default=True, type=str2bool,\n",
    "                    help='Cleanup and remove results files following eval')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "if not os.path.exists(args.save_folder):\n",
    "    os.mkdir(args.save_folder)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if args.cuda:\n",
    "        torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    if not args.cuda:\n",
    "        print(\"WARNING: It looks like you have a CUDA device, but aren't using \\\n",
    "              CUDA.  Run with --cuda for optimal eval speed.\")\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "annopath = os.path.join(args.voc_root, 'VOC2007', 'Annotations', '%s.xml')\n",
    "imgpath = os.path.join(args.voc_root, 'VOC2007', 'JPEGImages', '%s.jpg')\n",
    "imgsetpath = os.path.join(args.voc_root, 'VOC2007', 'ImageSets',\n",
    "                          'Main', '{:s}.txt')\n",
    "YEAR = '2007'\n",
    "devkit_path = args.voc_root + 'VOC' + YEAR\n",
    "dataset_mean = (104, 117, 123)\n",
    "set_type = 'test'\n",
    "\n",
    "\n",
    "class Timer(object):\n",
    "    \"\"\"A simple timer.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.total_time = 0.\n",
    "        self.calls = 0\n",
    "        self.start_time = 0.\n",
    "        self.diff = 0.\n",
    "        self.average_time = 0.\n",
    "\n",
    "    def tic(self):\n",
    "        # using time.time instead of time.clock because time time.clock\n",
    "        # does not normalize for multithreading\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def toc(self, average=True):\n",
    "        self.diff = time.time() - self.start_time\n",
    "        self.total_time += self.diff\n",
    "        self.calls += 1\n",
    "        self.average_time = self.total_time / self.calls\n",
    "        if average:\n",
    "            return self.average_time\n",
    "        else:\n",
    "            return self.diff\n",
    "\n",
    "\n",
    "def parse_rec(filename):\n",
    "    \"\"\" Parse a PASCAL VOC xml file \"\"\"\n",
    "    tree = ET.parse(filename)\n",
    "    objects = []\n",
    "    for obj in tree.findall('object'):\n",
    "        obj_struct = {}\n",
    "        obj_struct['name'] = obj.find('name').text\n",
    "        obj_struct['pose'] = obj.find('pose').text\n",
    "        obj_struct['truncated'] = int(obj.find('truncated').text)\n",
    "        obj_struct['difficult'] = int(obj.find('difficult').text)\n",
    "        bbox = obj.find('bndbox')\n",
    "        obj_struct['bbox'] = [int(bbox.find('xmin').text) - 1,\n",
    "                              int(bbox.find('ymin').text) - 1,\n",
    "                              int(bbox.find('xmax').text) - 1,\n",
    "                              int(bbox.find('ymax').text) - 1]\n",
    "        objects.append(obj_struct)\n",
    "\n",
    "    return objects\n",
    "\n",
    "\n",
    "def get_output_dir(name, phase):\n",
    "    \"\"\"Return the directory where experimental artifacts are placed.\n",
    "    If the directory does not exist, it is created.\n",
    "    A canonical path is built using the name from an imdb and a network\n",
    "    (if not None).\n",
    "    \"\"\"\n",
    "    filedir = os.path.join(name, phase)\n",
    "    if not os.path.exists(filedir):\n",
    "        os.makedirs(filedir)\n",
    "    return filedir\n",
    "\n",
    "\n",
    "def get_voc_results_file_template(image_set, cls):\n",
    "    # VOCdevkit/VOC2007/results/det_test_aeroplane.txt\n",
    "    filename = 'det_' + image_set + '_%s.txt' % (cls)\n",
    "    filedir = os.path.join(devkit_path, 'results')\n",
    "    if not os.path.exists(filedir):\n",
    "        os.makedirs(filedir)\n",
    "    path = os.path.join(filedir, filename)\n",
    "    return path\n",
    "\n",
    "\n",
    "def write_voc_results_file(all_boxes, dataset):\n",
    "    for cls_ind, cls in enumerate(labelmap):\n",
    "        print('Writing {:s} VOC results file'.format(cls))\n",
    "        filename = get_voc_results_file_template(set_type, cls)\n",
    "        with open(filename, 'wt') as f:\n",
    "            for im_ind, index in enumerate(dataset.ids):\n",
    "                dets = all_boxes[cls_ind+1][im_ind]\n",
    "                if dets == []:\n",
    "                    continue\n",
    "                # the VOCdevkit expects 1-based indices\n",
    "                for k in range(dets.shape[0]):\n",
    "                    f.write('{:s} {:.3f} {:.1f} {:.1f} {:.1f} {:.1f}\\n'.\n",
    "                            format(index[1], dets[k, -1],\n",
    "                                   dets[k, 0] + 1, dets[k, 1] + 1,\n",
    "                                   dets[k, 2] + 1, dets[k, 3] + 1))\n",
    "\n",
    "\n",
    "def do_python_eval(output_dir='output', use_07=True):\n",
    "    cachedir = os.path.join(devkit_path, 'annotations_cache')\n",
    "    aps = []\n",
    "    # The PASCAL VOC metric changed in 2010\n",
    "    use_07_metric = use_07\n",
    "    print('VOC07 metric? ' + ('Yes' if use_07_metric else 'No'))\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    for i, cls in enumerate(labelmap):\n",
    "        filename = get_voc_results_file_template(set_type, cls)\n",
    "        rec, prec, ap = voc_eval(\n",
    "           filename, annopath, imgsetpath.format(set_type), cls, cachedir,\n",
    "           ovthresh=0.5, use_07_metric=use_07_metric)\n",
    "        aps += [ap]\n",
    "        print('AP for {} = {:.4f}'.format(cls, ap))\n",
    "        with open(os.path.join(output_dir, cls + '_pr.pkl'), 'wb') as f:\n",
    "            pickle.dump({'rec': rec, 'prec': prec, 'ap': ap}, f)\n",
    "    print('Mean AP = {:.4f}'.format(np.mean(aps)))\n",
    "    print('~~~~~~~~')\n",
    "    print('Results:')\n",
    "    for ap in aps:\n",
    "        print('{:.3f}'.format(ap))\n",
    "    print('{:.3f}'.format(np.mean(aps)))\n",
    "    print('~~~~~~~~')\n",
    "    print('')\n",
    "    print('--------------------------------------------------------------')\n",
    "    print('Results computed with the **unofficial** Python eval code.')\n",
    "    print('Results should be very close to the official MATLAB eval code.')\n",
    "    print('--------------------------------------------------------------')\n",
    "\n",
    "\n",
    "def voc_ap(rec, prec, use_07_metric=True):\n",
    "    \"\"\" ap = voc_ap(rec, prec, [use_07_metric])\n",
    "    Compute VOC AP given precision and recall.\n",
    "    If use_07_metric is true, uses the\n",
    "    VOC 07 11 point method (default:True).\n",
    "    \"\"\"\n",
    "    if use_07_metric:\n",
    "        # 11 point metric\n",
    "        ap = 0.\n",
    "        for t in np.arange(0., 1.1, 0.1):\n",
    "            if np.sum(rec >= t) == 0:\n",
    "                p = 0\n",
    "            else:\n",
    "                p = np.max(prec[rec >= t])\n",
    "            ap = ap + p / 11.\n",
    "    else:\n",
    "        # correct AP calculation\n",
    "        # first append sentinel values at the end\n",
    "        mrec = np.concatenate(([0.], rec, [1.]))\n",
    "        mpre = np.concatenate(([0.], prec, [0.]))\n",
    "\n",
    "        # compute the precision envelope\n",
    "        for i in range(mpre.size - 1, 0, -1):\n",
    "            mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "\n",
    "        # to calculate area under PR curve, look for points\n",
    "        # where X axis (recall) changes value\n",
    "        i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "\n",
    "        # and sum (\\Delta recall) * prec\n",
    "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap\n",
    "\n",
    "\n",
    "def voc_eval(detpath,\n",
    "             annopath,\n",
    "             imagesetfile,\n",
    "             classname,\n",
    "             cachedir,\n",
    "             ovthresh=0.5,\n",
    "             use_07_metric=True):\n",
    "    \"\"\"rec, prec, ap = voc_eval(detpath,\n",
    "                           annopath,\n",
    "                           imagesetfile,\n",
    "                           classname,\n",
    "                           [ovthresh],\n",
    "                           [use_07_metric])\n",
    "Top level function that does the PASCAL VOC evaluation.\n",
    "detpath: Path to detections\n",
    "   detpath.format(classname) should produce the detection results file.\n",
    "annopath: Path to annotations\n",
    "   annopath.format(imagename) should be the xml annotations file.\n",
    "imagesetfile: Text file containing the list of images, one image per line.\n",
    "classname: Category name (duh)\n",
    "cachedir: Directory for caching the annotations\n",
    "[ovthresh]: Overlap threshold (default = 0.5)\n",
    "[use_07_metric]: Whether to use VOC07's 11 point AP computation\n",
    "   (default True)\n",
    "\"\"\"\n",
    "# assumes detections are in detpath.format(classname)\n",
    "# assumes annotations are in annopath.format(imagename)\n",
    "# assumes imagesetfile is a text file with each line an image name\n",
    "# cachedir caches the annotations in a pickle file\n",
    "# first load gt\n",
    "    if not os.path.isdir(cachedir):\n",
    "        os.mkdir(cachedir)\n",
    "    cachefile = os.path.join(cachedir, 'annots.pkl')\n",
    "    # read list of images\n",
    "    with open(imagesetfile, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    imagenames = [x.strip() for x in lines]\n",
    "    if not os.path.isfile(cachefile):\n",
    "        # load annots\n",
    "        recs = {}\n",
    "        for i, imagename in enumerate(imagenames):\n",
    "            recs[imagename] = parse_rec(annopath % (imagename))\n",
    "            if i % 100 == 0:\n",
    "                print('Reading annotation for {:d}/{:d}'.format(\n",
    "                   i + 1, len(imagenames)))\n",
    "        # save\n",
    "        print('Saving cached annotations to {:s}'.format(cachefile))\n",
    "        with open(cachefile, 'wb') as f:\n",
    "            pickle.dump(recs, f)\n",
    "    else:\n",
    "        # load\n",
    "        with open(cachefile, 'rb') as f:\n",
    "            recs = pickle.load(f)\n",
    "\n",
    "    # extract gt objects for this class\n",
    "    class_recs = {}\n",
    "    npos = 0\n",
    "    for imagename in imagenames:\n",
    "        R = [obj for obj in recs[imagename] if obj['name'] == classname]\n",
    "        bbox = np.array([x['bbox'] for x in R])\n",
    "        difficult = np.array([x['difficult'] for x in R]).astype(np.bool)\n",
    "        det = [False] * len(R)\n",
    "        npos = npos + sum(~difficult)\n",
    "        class_recs[imagename] = {'bbox': bbox,\n",
    "                                 'difficult': difficult,\n",
    "                                 'det': det}\n",
    "\n",
    "    # read dets\n",
    "    detfile = detpath.format(classname)\n",
    "    with open(detfile, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    if any(lines) == 1:\n",
    "\n",
    "        splitlines = [x.strip().split(' ') for x in lines]\n",
    "        image_ids = [x[0] for x in splitlines]\n",
    "        confidence = np.array([float(x[1]) for x in splitlines])\n",
    "        BB = np.array([[float(z) for z in x[2:]] for x in splitlines])\n",
    "\n",
    "        # sort by confidence\n",
    "        sorted_ind = np.argsort(-confidence)\n",
    "        sorted_scores = np.sort(-confidence)\n",
    "        BB = BB[sorted_ind, :]\n",
    "        image_ids = [image_ids[x] for x in sorted_ind]\n",
    "\n",
    "        # go down dets and mark TPs and FPs\n",
    "        nd = len(image_ids)\n",
    "        tp = np.zeros(nd)\n",
    "        fp = np.zeros(nd)\n",
    "        for d in range(nd):\n",
    "            R = class_recs[image_ids[d]]\n",
    "            bb = BB[d, :].astype(float)\n",
    "            ovmax = -np.inf\n",
    "            BBGT = R['bbox'].astype(float)\n",
    "            if BBGT.size > 0:\n",
    "                # compute overlaps\n",
    "                # intersection\n",
    "                ixmin = np.maximum(BBGT[:, 0], bb[0])\n",
    "                iymin = np.maximum(BBGT[:, 1], bb[1])\n",
    "                ixmax = np.minimum(BBGT[:, 2], bb[2])\n",
    "                iymax = np.minimum(BBGT[:, 3], bb[3])\n",
    "                iw = np.maximum(ixmax - ixmin, 0.)\n",
    "                ih = np.maximum(iymax - iymin, 0.)\n",
    "                inters = iw * ih\n",
    "                uni = ((bb[2] - bb[0]) * (bb[3] - bb[1]) +\n",
    "                       (BBGT[:, 2] - BBGT[:, 0]) *\n",
    "                       (BBGT[:, 3] - BBGT[:, 1]) - inters)\n",
    "                overlaps = inters / uni\n",
    "                ovmax = np.max(overlaps)\n",
    "                jmax = np.argmax(overlaps)\n",
    "\n",
    "            if ovmax > ovthresh:\n",
    "                if not R['difficult'][jmax]:\n",
    "                    if not R['det'][jmax]:\n",
    "                        tp[d] = 1.\n",
    "                        R['det'][jmax] = 1\n",
    "                    else:\n",
    "                        fp[d] = 1.\n",
    "            else:\n",
    "                fp[d] = 1.\n",
    "\n",
    "        # compute precision recall\n",
    "        fp = np.cumsum(fp)\n",
    "        tp = np.cumsum(tp)\n",
    "        rec = tp / float(npos)\n",
    "        # avoid divide by zero in case the first detection matches a difficult\n",
    "        # ground truth\n",
    "        prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n",
    "        ap = voc_ap(rec, prec, use_07_metric)\n",
    "    else:\n",
    "        rec = -1.\n",
    "        prec = -1.\n",
    "        ap = -1.\n",
    "\n",
    "    return rec, prec, ap\n",
    "\n",
    "\n",
    "def test_net(save_folder, net, cuda, dataset, transform, top_k,\n",
    "             im_size=300, thresh=0.05):\n",
    "    num_images = len(dataset)\n",
    "    # all detections are collected into:\n",
    "    #    all_boxes[cls][image] = N x 5 array of detections in\n",
    "    #    (x1, y1, x2, y2, score)\n",
    "    all_boxes = [[[] for _ in range(num_images)]\n",
    "                 for _ in range(len(labelmap)+1)]\n",
    "\n",
    "    # timers\n",
    "    _t = {'im_detect': Timer(), 'misc': Timer()}\n",
    "    output_dir = get_output_dir('ssd300_120000', set_type)\n",
    "    det_file = os.path.join(output_dir, 'detections.pkl')\n",
    "\n",
    "    for i in range(num_images):\n",
    "        im, gt, h, w = dataset.pull_item(i)\n",
    "\n",
    "        x = Variable(im.unsqueeze(0))\n",
    "        if args.cuda:\n",
    "            x = x.cuda()\n",
    "        _t['im_detect'].tic()\n",
    "        detections = net(x).data\n",
    "        detect_time = _t['im_detect'].toc(average=False)\n",
    "\n",
    "        # skip j = 0, because it's the background class\n",
    "        for j in range(1, detections.size(1)):\n",
    "            dets = detections[0, j, :]\n",
    "            mask = dets[:, 0].gt(0.).expand(5, dets.size(0)).t()\n",
    "            dets = torch.masked_select(dets, mask).view(-1, 5)\n",
    "            if dets.size(0) == 0:\n",
    "                continue\n",
    "            boxes = dets[:, 1:]\n",
    "            boxes[:, 0] *= w\n",
    "            boxes[:, 2] *= w\n",
    "            boxes[:, 1] *= h\n",
    "            boxes[:, 3] *= h\n",
    "            scores = dets[:, 0].cpu().numpy()\n",
    "            cls_dets = np.hstack((boxes.cpu().numpy(),\n",
    "                                  scores[:, np.newaxis])).astype(np.float32,\n",
    "                                                                 copy=False)\n",
    "            all_boxes[j][i] = cls_dets\n",
    "\n",
    "        print('im_detect: {:d}/{:d} {:.3f}s'.format(i + 1,\n",
    "                                                    num_images, detect_time))\n",
    "\n",
    "    with open(det_file, 'wb') as f:\n",
    "        pickle.dump(all_boxes, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    print('Evaluating detections')\n",
    "    evaluate_detections(all_boxes, output_dir, dataset)\n",
    "\n",
    "\n",
    "def evaluate_detections(box_list, output_dir, dataset):\n",
    "    write_voc_results_file(box_list, dataset)\n",
    "    do_python_eval(output_dir)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # load net\n",
    "    num_classes = len(labelmap) + 1                      # +1 for background\n",
    "    net = build_ssd('test', 300, num_classes)            # initialize SSD\n",
    "    net.load_state_dict(torch.load(args.trained_model))\n",
    "    net.eval()\n",
    "    print('Finished loading model!')\n",
    "    # load data\n",
    "    dataset = VOCDetection(args.voc_root, [('2007', set_type)],\n",
    "                           BaseTransform(300, dataset_mean),\n",
    "                           VOCAnnotationTransform())\n",
    "    if args.cuda:\n",
    "        net = net.cuda()\n",
    "        cudnn.benchmark = True\n",
    "    # evaluation\n",
    "    test_net(args.save_folder, net, args.cuda, dataset,\n",
    "             BaseTransform(net.size, dataset_mean), args.top_k, 300,\n",
    "             thresh=args.confidence_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from data import VOC_ROOT, VOC_CLASSES as labelmap\n",
    "from PIL import Image\n",
    "from data import VOCAnnotationTransform, VOCDetection, BaseTransform, VOC_CLASSES\n",
    "import torch.utils.data as data\n",
    "from ssd import build_ssd\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Single Shot MultiBox Detection')\n",
    "parser.add_argument('--trained_model', default='weights/ssd_300_VOC0712.pth',\n",
    "                    type=str, help='Trained state_dict file path to open')\n",
    "parser.add_argument('--save_folder', default='eval/', type=str,\n",
    "                    help='Dir to save results')\n",
    "parser.add_argument('--visual_threshold', default=0.6, type=float,\n",
    "                    help='Final confidence threshold')\n",
    "parser.add_argument('--cuda', default=True, type=bool,\n",
    "                    help='Use cuda to train model')\n",
    "parser.add_argument('--voc_root', default=VOC_ROOT, help='Location of VOC root directory')\n",
    "parser.add_argument('-f', default=None, type=str, help=\"Dummy arg so we can load in Jupyter Notebooks\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.cuda and torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "if not os.path.exists(args.save_folder):\n",
    "    os.mkdir(args.save_folder)\n",
    "\n",
    "\n",
    "def test_net(save_folder, net, cuda, testset, transform, thresh):\n",
    "    # dump predictions and assoc. ground truth to text file for now\n",
    "    filename = save_folder+'test1.txt'\n",
    "    num_images = len(testset)\n",
    "    for i in range(num_images):\n",
    "        print('Testing image {:d}/{:d}....'.format(i+1, num_images))\n",
    "        img = testset.pull_image(i)\n",
    "        img_id, annotation = testset.pull_anno(i)\n",
    "        x = torch.from_numpy(transform(img)[0]).permute(2, 0, 1)\n",
    "        x = Variable(x.unsqueeze(0))\n",
    "\n",
    "        with open(filename, mode='a') as f:\n",
    "            f.write('\\nGROUND TRUTH FOR: '+img_id+'\\n')\n",
    "            for box in annotation:\n",
    "                f.write('label: '+' || '.join(str(b) for b in box)+'\\n')\n",
    "        if cuda:\n",
    "            x = x.cuda()\n",
    "\n",
    "        y = net(x)      # forward pass\n",
    "        detections = y.data\n",
    "        # scale each detection back up to the image\n",
    "        scale = torch.Tensor([img.shape[1], img.shape[0],\n",
    "                             img.shape[1], img.shape[0]])\n",
    "        pred_num = 0\n",
    "        for i in range(detections.size(1)):\n",
    "            j = 0\n",
    "            while detections[0, i, j, 0] >= 0.6:\n",
    "                if pred_num == 0:\n",
    "                    with open(filename, mode='a') as f:\n",
    "                        f.write('PREDICTIONS: '+'\\n')\n",
    "                score = detections[0, i, j, 0]\n",
    "                label_name = labelmap[i-1]\n",
    "                pt = (detections[0, i, j, 1:]*scale).cpu().numpy()\n",
    "                coords = (pt[0], pt[1], pt[2], pt[3])\n",
    "                pred_num += 1\n",
    "                with open(filename, mode='a') as f:\n",
    "                    f.write(str(pred_num)+' label: '+label_name+' score: ' +\n",
    "                            str(score) + ' '+' || '.join(str(c) for c in coords) + '\\n')\n",
    "                j += 1\n",
    "\n",
    "\n",
    "def test_voc():\n",
    "    # load net\n",
    "    num_classes = len(VOC_CLASSES) + 1 # +1 background\n",
    "    net = build_ssd('test', 300, num_classes) # initialize SSD\n",
    "    net.load_state_dict(torch.load(args.trained_model))\n",
    "    net.eval()\n",
    "    print('Finished loading model!')\n",
    "    # load data\n",
    "    testset = VOCDetection(args.voc_root, [('2007', 'test')], None, VOCAnnotationTransform())\n",
    "    if args.cuda:\n",
    "        net = net.cuda()\n",
    "        cudnn.benchmark = True\n",
    "    # evaluation\n",
    "    test_net(args.save_folder, net, args.cuda, testset,\n",
    "             BaseTransform(net.size, (104, 117, 123)),\n",
    "             thresh=args.visual_threshold)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_voc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
